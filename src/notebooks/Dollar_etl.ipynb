{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "from uuid import uuid4\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"jdbc:postgresql://db:5432/fuel_analysis\"\n",
    "properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uuid():\n",
    "    return str(uuid4())\n",
    "\n",
    "uuid_udf = f.udf(lambda: create_uuid(), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Dolar ETL\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars\", \"/usr/local/spark/jars/postgresql-42.7.3.jar\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(path):\n",
    "  df = spark.read.csv(path, sep=';', inferSchema=True, header=True)\n",
    "  \n",
    "  return df\n",
    "\n",
    "def transform_data(df):\n",
    "    df = df.withColumn(\n",
    "        \"data\",\n",
    "        f.to_date(f.col(\"data\").cast(StringType()), 'dd/MM/yyyy')\n",
    "        )\\\n",
    "        .withColumn('valor', f.regexp_replace('valor', ',', '.'))\\\n",
    "        .withColumn('valor', f.col('valor').cast(DoubleType()))\\\n",
    "        .withColumn('dia', f.dayofmonth(f.col('data')))\\\n",
    "        .withColumn('mes', f.month(f.col('data')))\\\n",
    "        .withColumn('ano', f.year(f.col('data')))\\\n",
    "        .withColumn('dia_semana', f.dayofweek(f.col('data')))\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/jovyan/data/'\n",
    "path = base_path+'dolar-data-jan-2004-to-dez-2023.csv'\n",
    "df = extract_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_info = transform_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_info.write.jdbc(url=url, table=\"dollar_info\", mode=\"append\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dim_table(table_name):\n",
    "    return spark.read.jdbc(url=url, table=table_name, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doll = load_dim_table(\"dollar_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---+---+----+----------+--------------------+\n",
      "|           dollar_id|      data|dia|mes| ano|dia_semana|               valor|\n",
      "+--------------------+----------+---+---+----+----------+--------------------+\n",
      "|e27f326a-4bf4-461...|2003-12-31| 31| 12|2003|         4|2.888400000000000000|\n",
      "|260e974a-3753-494...|2004-01-02|  2|  1|2004|         6|2.885400000000000000|\n",
      "|ed7eacbf-8e74-49b...|2004-01-05|  5|  1|2004|         2|2.861900000000000000|\n",
      "|72fd723f-78e1-4a8...|2004-01-06|  6|  1|2004|         3|2.850000000000000000|\n",
      "|65df32b4-ddf5-425...|2004-01-07|  7|  1|2004|         4|2.871500000000000000|\n",
      "|e779a80f-c268-49d...|2004-01-08|  8|  1|2004|         5|2.858000000000000000|\n",
      "|d2c4f914-407b-46b...|2004-01-09|  9|  1|2004|         6|2.841400000000000000|\n",
      "|cc26f5a3-4e8d-4db...|2004-01-12| 12|  1|2004|         2|2.815500000000000000|\n",
      "|8f124029-8873-4f5...|2004-01-13| 13|  1|2004|         3|2.801400000000000000|\n",
      "|e84f638b-81a0-4a6...|2004-01-14| 14|  1|2004|         4|2.813400000000000000|\n",
      "|42b912cd-f39e-4a3...|2004-01-15| 15|  1|2004|         5|2.811800000000000000|\n",
      "|2ce3960f-eccc-450...|2004-01-16| 16|  1|2004|         6|2.817600000000000000|\n",
      "|1de4b630-f162-400...|2004-01-19| 19|  1|2004|         2|2.841100000000000000|\n",
      "|323d8d9a-f55f-404...|2004-01-20| 20|  1|2004|         3|2.837400000000000000|\n",
      "|c29777c0-3874-4d6...|2004-01-21| 21|  1|2004|         4|2.840900000000000000|\n",
      "|d45164e1-0496-443...|2004-01-22| 22|  1|2004|         5|2.840900000000000000|\n",
      "|d773a2ca-af0e-4a7...|2004-01-23| 23|  1|2004|         6|2.842700000000000000|\n",
      "|c855f02c-cd1c-494...|2004-01-26| 26|  1|2004|         2|2.842300000000000000|\n",
      "|0870b2e1-c0de-4a7...|2004-01-27| 27|  1|2004|         3|2.857900000000000000|\n",
      "|ea47f6ef-61fa-498...|2004-01-28| 28|  1|2004|         4|2.877700000000000000|\n",
      "+--------------------+----------+---+---+----+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doll.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
